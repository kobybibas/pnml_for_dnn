{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../output/analysis_pnml_from_pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/pnml_for_dnn/notebooks/pnml_from_pretrained.ipynb Cell 1'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2/home/ubuntu/pnml_for_dnn/notebooks/pnml_from_pretrained.ipynb#ch0000000vscode-remote?line=12'>13</a>\u001b[0m api \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39mApi()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2/home/ubuntu/pnml_for_dnn/notebooks/pnml_from_pretrained.ipynb#ch0000000vscode-remote?line=13'>14</a>\u001b[0m out_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../output/analysis_pnml_from_pretrained\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bec2/home/ubuntu/pnml_for_dnn/notebooks/pnml_from_pretrained.ipynb#ch0000000vscode-remote?line=14'>15</a>\u001b[0m os\u001b[39m.\u001b[39;49mmakedirs(out_dir, exist_ok\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2/home/ubuntu/pnml_for_dnn/notebooks/pnml_from_pretrained.ipynb#ch0000000vscode-remote?line=16'>17</a>\u001b[0m \u001b[39m# Project is specified by <entity/project-name>\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bec2/home/ubuntu/pnml_for_dnn/notebooks/pnml_from_pretrained.ipynb#ch0000000vscode-remote?line=17'>18</a>\u001b[0m runs \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mruns(\u001b[39m\"\u001b[39m\u001b[39mkobybibas/pnml_for_dnn\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pnml_for_dnn/lib/python3.8/os.py:223\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ubuntu/anaconda3/envs/pnml_for_dnn/lib/python3.8/os.py?line=220'>221</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/anaconda3/envs/pnml_for_dnn/lib/python3.8/os.py?line=221'>222</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/ubuntu/anaconda3/envs/pnml_for_dnn/lib/python3.8/os.py?line=222'>223</a>\u001b[0m     mkdir(name, mode)\n\u001b[1;32m    <a href='file:///home/ubuntu/anaconda3/envs/pnml_for_dnn/lib/python3.8/os.py?line=223'>224</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ubuntu/anaconda3/envs/pnml_for_dnn/lib/python3.8/os.py?line=224'>225</a>\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/anaconda3/envs/pnml_for_dnn/lib/python3.8/os.py?line=225'>226</a>\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ubuntu/anaconda3/envs/pnml_for_dnn/lib/python3.8/os.py?line=226'>227</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../output/analysis_pnml_from_pretrained'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import matplotlib\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "plt.style.use([\"science\", \"ieee\"])\n",
    "api = wandb.Api()\n",
    "out_dir = \"../output/analysis_pnml_from_pretrained\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Project is specified by <entity/project-name>\n",
    "runs = api.runs(\"kobybibas/pnml_for_dnn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 600\n",
    "if False: # 3 epochs\n",
    "    # prune 0.7\n",
    "    run = api.run(\"kobybibas/pnml_for_dnn/kqitnlwh\")\n",
    "    run.file(\"res_df.pkl\").download(replace=True)\n",
    "    prune_0_df = pd.read_pickle(\"res_df.pkl\")\n",
    "\n",
    "    # prune 0.8\n",
    "    run = api.run(\"kobybibas/pnml_for_dnn/i7flad6i\")\n",
    "    run.file(\"res_df.pkl\").download(replace=True)\n",
    "    prune_1_df = pd.read_pickle(\"res_df.pkl\")\n",
    "\n",
    "    # prune 0.9\n",
    "    run = api.run(\"kobybibas/pnml_for_dnn/3o6srigx\")\n",
    "    run.file(\"res_df.pkl\").download(replace=True)\n",
    "    prune_2_df = pd.read_pickle(\"res_df.pkl\")\n",
    "\n",
    "    # prune 0.95\n",
    "    run = api.run(\"kobybibas/pnml_for_dnn/3htljc6s\")\n",
    "    run.file(\"res_df.pkl\").download(replace=True)\n",
    "    prune_3_df = pd.read_pickle(\"res_df.pkl\")\n",
    "\n",
    "    # prune 0.99\n",
    "    run = api.run(\"kobybibas/pnml_for_dnn/11auktcw\")\n",
    "    run.file(\"res_df.pkl\").download(replace=True)\n",
    "    prune_4_df = pd.read_pickle(\"res_df.pkl\")\n",
    "\n",
    "else:\n",
    "    # prune 0.7\n",
    "    run = api.run(\"kobybibas/pnml_for_dnn/mbqz5e61\")\n",
    "    run.file(\"res_df.pkl\").download(replace=True)\n",
    "    prune_0_df = pd.read_pickle(\"res_df.pkl\").iloc[:total_samples]\n",
    "\n",
    "    # prune 0.8\n",
    "    run = api.run(\"kobybibas/pnml_for_dnn/1guf6xf2\")\n",
    "    run.file(\"res_df.pkl\").download(replace=True)\n",
    "    prune_1_df = pd.read_pickle(\"res_df.pkl\").iloc[:total_samples]\n",
    "\n",
    "    # prune 0.9\n",
    "    run = api.run(\"kobybibas/pnml_for_dnn/1lrf17di\")\n",
    "    run.file(\"res_df.pkl\").download(replace=True)\n",
    "    prune_2_df = pd.read_pickle(\"res_df.pkl\").iloc[:total_samples]\n",
    "\n",
    "    # prune 0.95\n",
    "    run = api.run(\"kobybibas/pnml_for_dnn/1t1ydpao\")\n",
    "    run.file(\"res_df.pkl\").download(replace=True)\n",
    "    prune_3_df = pd.read_pickle(\"res_df.pkl\").iloc[:total_samples]\n",
    "\n",
    "    # prune 0.99\n",
    "    run = api.run(\"kobybibas/pnml_for_dnn/3swolu27\")\n",
    "    run.file(\"res_df.pkl\").download(replace=True)\n",
    "    prune_4_df = pd.read_pickle(\"res_df.pkl\").iloc[:total_samples]\n",
    "\n",
    "df_dict = {\n",
    "    \"0.7\": prune_0_df,\n",
    "    \"0.8\": prune_1_df,\n",
    "    \"0.9\": prune_2_df,\n",
    "    \"0.95\": prune_3_df,\n",
    "    \"0.99\": prune_4_df,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pNML accuracy (%)</th>\n",
       "      <th>ERM accuracy (%)</th>\n",
       "      <th>pNML logloss</th>\n",
       "      <th>ERM logloss</th>\n",
       "      <th>pNML max logloss</th>\n",
       "      <th>ERM max logloss</th>\n",
       "      <th>Regret</th>\n",
       "      <th>Test set size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prune amount</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>94.17</td>\n",
       "      <td>94.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.24</td>\n",
       "      <td>10.36</td>\n",
       "      <td>14.47</td>\n",
       "      <td>0.06</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>94.33</td>\n",
       "      <td>95.17</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.18</td>\n",
       "      <td>10.09</td>\n",
       "      <td>11.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>93.83</td>\n",
       "      <td>93.83</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>11.07</td>\n",
       "      <td>13.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>96.50</td>\n",
       "      <td>96.33</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10.62</td>\n",
       "      <td>11.69</td>\n",
       "      <td>0.02</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.99</th>\n",
       "      <td>91.33</td>\n",
       "      <td>91.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>5.36</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pNML accuracy (%)  ERM accuracy (%)  pNML logloss  ERM logloss  \\\n",
       "Prune amount                                                                   \n",
       "0.7                       94.17             94.17          0.16         0.24   \n",
       "0.8                       94.33             95.17          0.13         0.18   \n",
       "0.9                       93.83             93.83          0.18         0.25   \n",
       "0.95                      96.50             96.33          0.13         0.15   \n",
       "0.99                      91.33             91.00          0.22         0.22   \n",
       "\n",
       "              pNML max logloss  ERM max logloss  Regret  Test set size  \n",
       "Prune amount                                                            \n",
       "0.7                      10.36            14.47    0.06            600  \n",
       "0.8                      10.09            11.76    0.04            600  \n",
       "0.9                      11.07            13.97    0.05            600  \n",
       "0.95                     10.62            11.69    0.02            600  \n",
       "0.99                      5.36             5.52    0.00            600  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_list = []\n",
    "for prune_amount, df in df_dict.items():\n",
    "    performance_list.append(\n",
    "        {\n",
    "            \"Prune amount\": prune_amount,\n",
    "            \"pNML accuracy (%)\": 100 * df[\"pnml_is_correct\"].mean(),\n",
    "            \"ERM accuracy (%)\": 100 * df[\"erm_is_correct\"].mean(),\n",
    "            \"pNML logloss\": df[\"pnml_logloss\"].mean(),\n",
    "            \"ERM logloss\": df[\"erm_logloss\"].mean(),\n",
    "            \"pNML max logloss\": df[\"pnml_logloss\"].max(),\n",
    "            \"ERM max logloss\": df[\"erm_logloss\"].max(),\n",
    "            \"Regret\": df[\"pnml_regret\"].mean(),\n",
    "            'Test set size': len(df)\n",
    "        }\n",
    "    )\n",
    "\n",
    "performance_df = pd.DataFrame(performance_list).round(2).set_index(\"Prune amount\")\n",
    "performance_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max regret_max=0.661. Theoretical max: np.log(2)=0.693. Difference=regret_max-np.log(2)=-0.032520649912667454 \n"
     ]
    }
   ],
   "source": [
    "bins = np.linspace(0.0, np.log(2), 100)\n",
    "\n",
    "regret_max = max([df[\"pnml_regret\"].max() for df in df_dict.values()])\n",
    "print(\n",
    "    f\"Max {regret_max=:.3f}. Theoretical max: {np.log(2)=:.3f}. Difference={regret_max-np.log(2)=} \"\n",
    ")\n",
    "fig, axs = plt.subplots(len(df_dict), 1, dpi=200, sharex=True, sharey=True)\n",
    "\n",
    "for i, (prune_amount, df) in enumerate(df_dict.items()):\n",
    "    ax = axs[i]\n",
    "    ax.hist(\n",
    "        df[\"pnml_regret\"], bins=bins, alpha=1.0, color=f\"C0\",\n",
    "    )\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.text(\n",
    "        0.02,\n",
    "        0.85,\n",
    "        f\"Prune amount: {float(prune_amount):3.2f}\",\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "axs[-1].set_xlabel(\"Regret\")\n",
    "plt.xlim(0, np.log(2) + 0.05)\n",
    "plt.tight_layout()\n",
    "plt.savefig(osp.join(out_dir, \"regret_hist.pdf\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regret for pNML correctly classifed samples\n",
    "bins = np.linspace(0.0, np.log(2), 100)\n",
    "fig, axs = plt.subplots(len(df_dict), 1, dpi=200, sharex=True, sharey=True)\n",
    "\n",
    "for i, (prune_amount, df) in enumerate(df_dict.items()):\n",
    "    regret_for_correct = df[df['pnml_is_correct']==True][\"pnml_regret\"]\n",
    "    regret_for_incorrect = df[df['pnml_is_correct']==False][\"pnml_regret\"]\n",
    "\n",
    "    ax = axs[i]\n",
    "    ax.hist(\n",
    "        regret_for_incorrect, bins=bins, alpha=0.75, color=f\"C3\",label='pNML incorrectly classified',density=True\n",
    "    )\n",
    "    ax.hist(\n",
    "        regret_for_correct, bins=bins, alpha=0.25, color=f\"C2\",label='pNML correctly classified',density=True\n",
    "    )\n",
    "\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.text(\n",
    "        0.02,\n",
    "        0.85,\n",
    "        f\"Prune amount: {float(prune_amount):3.2f}\",\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "axs[-1].set_xlabel(\"Regret\")\n",
    "axs[0].legend(\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, 1.75),\n",
    "    frameon=True,\n",
    "    shadow=False,\n",
    "    ncol=2,\n",
    "    prop={\"size\": 6},\n",
    ")\n",
    "plt.xlim(0, np.log(2) + 0.05)\n",
    "plt.tight_layout()\n",
    "plt.savefig(osp.join(out_dir, \"regret_hist_for_pnml_correct_and_incorrect.pdf\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regret for ERM correctly classifed samples\n",
    "bins = np.linspace(0.0, np.log(2), 100)\n",
    "fig, axs = plt.subplots(len(df_dict), 1, dpi=200, sharex=True, sharey=True)\n",
    "\n",
    "for i, (prune_amount, df) in enumerate(df_dict.items()):\n",
    "    regret_for_correct = df[df[\"erm_is_correct\"] == True][\"pnml_regret\"]\n",
    "    regret_for_incorrect = df[df[\"erm_is_correct\"] == False][\"pnml_regret\"]\n",
    "\n",
    "    ax = axs[i]\n",
    "    ax.hist(\n",
    "        regret_for_incorrect,\n",
    "        bins=bins,\n",
    "        alpha=0.75,\n",
    "        color=f\"C3\",\n",
    "        label=\"ERM incorrectly classified\",\n",
    "        density=True\n",
    "    )\n",
    "    ax.hist(\n",
    "        regret_for_correct,\n",
    "        bins=bins,\n",
    "        alpha=0.25,\n",
    "        color=f\"C2\",\n",
    "        label=\"ERM correctly classified\",\n",
    "        density=True\n",
    "    )\n",
    "\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.text(\n",
    "        0.02,\n",
    "        0.85,\n",
    "        f\"Prune amount: {float(prune_amount):3.2f}\",\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "axs[-1].set_xlabel(\"Regret\")\n",
    "axs[0].legend(\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, 1.75),\n",
    "    frameon=True,\n",
    "    shadow=False,\n",
    "    ncol=2,\n",
    "    prop={\"size\": 6},\n",
    ")\n",
    "plt.xlim(0, np.log(2) + 0.05)\n",
    "plt.tight_layout()\n",
    "plt.savefig(osp.join(out_dir, \"regret_hist_for_erm_correct_and_incorrect.pdf\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logloss\n",
    "loss_max = max(\n",
    "    [df[\"pnml_logloss\"].max() for df in df_dict.values()]\n",
    "    + [df[\"erm_logloss\"].max() for df in df_dict.values()]\n",
    ")\n",
    "loss_min = min(\n",
    "    [df[\"pnml_logloss\"].min() for df in df_dict.values()]\n",
    "    + [df[\"erm_logloss\"].min() for df in df_dict.values()]\n",
    ")\n",
    "\n",
    "bins = np.logspace(-9, np.log10(loss_max), 100)\n",
    "bins = np.linspace(0.0, loss_max, 100)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(len(df_dict), 1, dpi=200, sharex=True, sharey=True)\n",
    "\n",
    "for i, (prune_amount, df) in enumerate(df_dict.items()):\n",
    "    ax = axs[i]\n",
    "    ax.hist(\n",
    "        df[\"pnml_logloss\"], bins=bins, label=f\"pNML\", alpha=1.0, color=\"C0\",\n",
    "    )\n",
    "    ax.hist(\n",
    "        df[\"erm_logloss\"], bins=bins, alpha=0.5, color=\"C1\", label=f\"ERM\",\n",
    "    )\n",
    "\n",
    "    ax.text(\n",
    "        0.975,\n",
    "        0.8,\n",
    "        f\"Prune amount: {float(prune_amount):3.2f}\",\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "axs[0].legend(\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, 1.75),\n",
    "    frameon=True,\n",
    "    shadow=False,\n",
    "    ncol=2,\n",
    "    prop={\"size\": 6},\n",
    ")\n",
    "axs[-1].set_xlabel(f\"Logloss\")\n",
    "axs[-1].set_xlim(left=0.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(osp.join(out_dir,'logloss_hist.pdf'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0.0, 1.0, 100)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(len(df_dict), 1, dpi=200, sharex=True, sharey=True)\n",
    "\n",
    "for i, (prune_amount, df) in enumerate(df_dict.items()):\n",
    "    pnml_probs_for_correct = df.apply(\n",
    "        lambda row: row[\"pnml_probs\"][int(row[\"test_true_label\"])], axis=1\n",
    "    )\n",
    "    erm_probs_for_correct = df.apply(\n",
    "        lambda row: row[\"erm_probs\"][int(row[\"test_true_label\"])], axis=1\n",
    "    )\n",
    "\n",
    "    ax = axs[i]\n",
    "    ax.hist(\n",
    "        pnml_probs_for_correct, bins=bins, label=f\"pNML\", alpha=1.0, color=\"C0\",\n",
    "    )\n",
    "    ax.hist(\n",
    "        erm_probs_for_correct, bins=bins, alpha=0.5, color=\"C1\", label=f\"ERM\",\n",
    "    )\n",
    "\n",
    "    ax.text(\n",
    "        0.02,\n",
    "        0.85,\n",
    "        f\"Prune amount: {float(prune_amount):3.2f}\",\n",
    "        ha=\"left\",\n",
    "        va=\"top\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "axs[0].legend(\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, 1.75),\n",
    "    frameon=True,\n",
    "    shadow=False,\n",
    "    ncol=2,\n",
    "    prop={\"size\": 6},\n",
    ")\n",
    "axs[-1].set_xlabel(f\"Probability assignment for the correct label\")\n",
    "axs[-1].set_xlim(left=0.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(osp.join(out_dir,'prob_for_correct_label_hist.pdf'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d9c88672f83962d885c1f91e72b980f4561184b3d38dc404dbf2d884f79af74"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('pnml_for_dnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
